# Daily Updates on 3D-Related Papers

This repository automatically fetches new or updated arXiv papers in the [cs.CV] category every day, checks if they are relevant to "3D reconstruction" or "3D generation" via ChatGPT, and lists them below.

## How It Works
1. A GitHub Actions workflow runs daily at 09:00 UTC.  
2. It uses the script [fetch_cv_3d_papers.py](fetch_cv_3d_papers.py) to:  
   - Retrieve the latest arXiv papers in cs.CV.  
   - Use ChatGPT to filter out those related to 3D reconstruction/generation.  
   - Update this README.md with the new findings.  
   - Send an email via 163 Mail if any relevant papers are found.  

# Paper List
## Arxiv 2025-01-31

Relavance | Title | Research Topic | Keywords | Pipeline
|------|---------------|----------------|----------|---------|
9.5 | [[9.5] 2501.19196v1 RaySplats: Ray Tracing based Gaussian Splatting](http://arxiv.org/abs/2501.19196v1) | 3D generation 三维生成 | 3D Gaussian Splatting<br>Ray Tracing<br>3D高斯点云<br>光线追踪 | input: 2D images 2D图像<br>process: Gaussian Splatting 高斯点云渲染<br>process: ray tracing based on Gaussian primitives 基于高斯原始体的光线追踪<br>output: 3D objects with light and shadow effects 输出具有光影效果的3D物体 |
9.0 | [[9.0] 2501.17978v2 VoD-3DGS: View-opacity-Dependent 3D Gaussian Splatting](http://arxiv.org/abs/2501.17978v2) | 3D generation 3D生成 | 3D Gaussian Splatting<br>view-dependent rendering<br>3D高斯点云<br>视角依赖的渲染 | input: 3D scene reconstruction from images 3D场景重建从图像中提取<br>step 1: extend 3D Gaussian Splatting model 扩展3D高斯点云模型<br>step 2: introduce symmetric matrix to enhance opacity representation 引入对称矩阵以增强不透明性表示<br>step 3: optimize suppression of Gaussians based on viewer perspective 根据观察者视角优化高斯的抑制<br>output: improved representation of view-dependent reflections and specular highlights 输出：改进视角依赖的反射和镜面高光的表示 |
8.5 | [[8.5] 2501.19319v1 Advancing Dense Endoscopic Reconstruction with Gaussian Splatting-driven Surface Normal-aware Tracking and Mapping](http://arxiv.org/abs/2501.19319v1) | 3D reconstruction  三维重建 | 3D Gaussian Splatting<br>SLAM<br>endoscopic reconstruction<br>depth reconstruction<br>3D 高斯点<br>SLAM<br>内窥镜重建<br>深度重建 | input: endoscopic images 内窥镜图像<br>step1: surface normal-aware tracking 表面法线感知跟踪<br>step2: accurate mapping 精确地图构建<br>step3: bundle adjustment 捆绑调整<br>output: geometrically accurate 3D reconstruction 准确的三维重建 |
8.5 | [[8.5] 2501.19252v1 Inference-Time Text-to-Video Alignment with Diffusion Latent Beam Search](http://arxiv.org/abs/2501.19252v1) | Video Generation 视频生成 | Text-to-video<br>Diffusion models<br>Video generation<br>评分调整<br>文本转视频<br>扩散模型<br>视频生成<br>奖励校准 | input: video generation prompts 视频生成提示<br>step1: employ diffusion latent beam search 使用扩散潜在光束搜索<br>step2: maximize alignment reward 最大化对齐奖励<br>step3: improve perceptual quality 提升感知质量<br>output: high-quality video optimized for natural movement 输出：高质量视频，优化自然运动 |
8.5 | [[8.5] 2501.19088v1 JGHand: Joint-Driven Animatable Hand Avater via 3D Gaussian Splatting](http://arxiv.org/abs/2501.19088v1) | 3D generation 3D生成 | 3D Gaussian Splatting<br>animatable hand avatar<br>3D高斯喷涂<br>可动画手部化身 | input: 3D key points 3D关键点<br>Jointly 3D Gaussian Splatting (3DGS) joint-driven representation 联合3D高斯喷涂（3DGS）驱动表示<br>apply spatial transformations based on 3D key points 基于3D关键点应用空间变换<br>real-time rendering and shadow simulation 实时渲染和阴影模拟<br>output: animatable high-fidelity hand images 输出：可动画的高保真手部图像 |
8.5 | [[8.5] 2501.18982v1 OmniPhysGS: 3D Constitutive Gaussians for General Physics-Based Dynamics Generation](http://arxiv.org/abs/2501.18982v1) | 3D generation 3D生成 | 3D generation<br>3D gaussian<br>3D生成<br>3D高斯 | input: user-specified prompts 用户指定的提示<br>step1: define a scene according to user prompts 根据用户提示定义场景<br>step2: estimate material weighting factors using a pretrained video diffusion model 使用预训练的视频扩散模型估计材料权重因子<br>step3: represent each 3D asset as a collection of constitutive 3D Gaussians 将每个3D资产表示为一组组成的3D高斯分布<br>output: a physics-based 3D dynamic scene 输出：基于物理的3D动态场景 |
8.0 | [[8.0] 2501.19270v1 Imagine with the Teacher: Complete Shape in a Multi-View Distillation Way](http://arxiv.org/abs/2501.19270v1) | 3D reconstruction三维重建 | Point Cloud Completion<br>Multi-view Distillation<br>3D Shape Recovery<br>点云补全<br>多视图蒸馏<br>3D形状恢复 | input: incomplete point cloud 输入: 不完整的点云<br>step1: apply autoencoder architecture 应用自编码器架构<br>step2: use knowledge distillation strategy to enhance completion 使用知识蒸馏策略以增强完成度<br>step3: output: completed point cloud 输出: 完整的点云 |
7.5 | [[7.5] 2501.19382v1 LiDAR Loop Closure Detection using Semantic Graphs with Graph Attention Networks](http://arxiv.org/abs/2501.19382v1) | Autonomous Driving 自主驾驶 | Loop Closure Detection<br>Semantic Graphs<br>Graph Attention Networks<br>闭环检测<br>语义图<br>图注意力网络 | input: point cloud 输入: 点云<br>step1: encode semantic graphs using graph attention networks 步骤1: 使用图注意力网络编码语义图<br>step2: generate graph vectors through self-attention mechanisms 步骤2: 通过自注意力机制生成图向量<br>step3: compare graph vectors to detect loop closure 步骤3: 比较图向量以检测闭环<br>output: loop closure candidates 输出: 闭环候选 |
7.5 | [[7.5] 2501.19035v1 SynthmanticLiDAR: A Synthetic Dataset for Semantic Segmentation on LiDAR Imaging](http://arxiv.org/abs/2501.19035v1) | Autonomous Driving 自主驾驶 | Semantic segmentation<br>LiDAR imaging<br>autonomous driving<br>合成分割<br>LiDAR成像<br>自主驾驶 | input: LiDAR images (输入: LiDAR图像)<br>modify CARLA simulator (修改CARLA模拟器)<br>generate SynthmanticLiDAR dataset (生成SynthmanticLiDAR数据集)<br>evaluate with transfer learning (使用迁移学习进行评估)<br>output: improved semantic segmentation performance (输出: 改进的语义分割性能) |
7.5 | [[7.5] 2501.17159v2 IC-Portrait: In-Context Matching for View-Consistent Personalized Portrait](http://arxiv.org/abs/2501.17159v2) | Image Generation 图像生成 | Personalized Portrait Generation<br>3D-aware relighting<br>个性化肖像生成<br>具3D感知的重光照 | Input: reference portrait images 参考肖像图像<br>Step 1: Lighting-Aware Stitching 具光照感知的拼接<br>Step 2: View-Consistent Adaptation 具视图一致的适配<br>Output: personalized portraits with identity preservation 具有身份保留的个性化肖像 |
7.0 | [[7.0] 2501.19243v1 Accelerating Diffusion Transformer via Error-Optimized Cache](http://arxiv.org/abs/2501.19243v1) | Image Generation 图像生成 | Image Generation<br>Diffusion Transformer<br>ImageNet Dataset<br>图像生成<br>扩散变换器<br>ImageNet数据集 | input: Diffusion Transformer features (扩散变换器特征)<br>extract caching differences (提取缓存差异)<br>optimize cache based on errors (基于错误优化缓存)<br>output: improved generated images (输出: 改进的生成图像) |
6.5 | [[6.5] 2501.19259v1 Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for Autonomous Drone FlighT at the Edge](http://arxiv.org/abs/2501.19259v1) | Autonomous Driving 自主驾驶 | autonomous driving<br>natural language processing<br>neuroscience<br>autonomous navigation<br>自主驾驶<br>自然语言处理<br>神经科学<br>自主导航 | input: human speech and dynamic environment 输入：人类语言和动态环境<br>step1: translate human speech into planning commands 步骤1：将人类语言翻译为规划命令<br>step2: navigate and avoid obstacles using neuromorphic vision 步骤2：利用神经形态视觉导航并避免障碍物<br>output: real-time autonomous navigation output 实时自主导航结果 |
6.5 | [[6.5] 2501.18994v1 VKFPos: A Learning-Based Monocular Positioning with Variational Bayesian Extended Kalman Filter Integration](http://arxiv.org/abs/2501.18994v1) | Autonomous Driving 自主驾驶 | monocular positioning<br>extended kalman filter<br>variational bayesian inference<br>单目定位<br>扩展卡尔曼滤波<br>变分贝叶斯推理 | input: monocular images 单目图像<br>step1: Absolute Pose Regression (APR) 绝对姿态回归<br>step2: Relative Pose Regression (RPR) 相对姿态回归<br>step3: Integration with Extended Kalman Filter (EKF) 通过扩展卡尔曼滤波整合<br>output: accurate positional predictions 准确的位置信息预测 |


## Arxiv 2025-01-30

Relavance | Title | Research Topic | Keywords | Pipeline
|------|---------------|----------------|----------|---------|
8.5 | [[8.5] 2501.18594v1 Foundational Models for 3D Point Clouds: A Survey and Outlook](http://arxiv.org/abs/2501.18594v1) | 3D reconstruction 3D重建 | 3D point clouds<br>foundational models<br>3D视觉理解<br>基础模型<br>3D点云 | input: 3D point clouds 3D点云<br>step1: review of foundational models FMs 基础模型的回顾<br>step2: categorize use of FMs in 3D tasks 分类基础模型在3D任务中的应用<br>step3: summarize state-of-the-art methods 总结最新的方法<br>output: comprehensive overview of FMs for 3D understanding 输出：基础模型在3D理解中的综合概述 |
8.5 | [[8.5] 2501.18162v1 IROAM: Improving Roadside Monocular 3D Object Detection Learning from Autonomous Vehicle Data Domain](http://arxiv.org/abs/2501.18162v1) | Autonomous Driving 自动驾驶 | 3D object detection<br>autonomous driving<br>3D对象检测<br>自动驾驶 | input: roadside data and vehicle-side data<br>In-Domain Query Interaction module learns content and depth information<br>Cross-Domain Query Enhancement decouples queries into semantic and geometry parts<br>outputs enhanced object queries |
8.5 | [[8.5] 2501.18110v1 Lifelong 3D Mapping Framework for Hand-held & Robot-mounted LiDAR Mapping Systems](http://arxiv.org/abs/2501.18110v1) | 3D reconstruction 三维重建 | 3D Mapping<br>3D Reconstruction<br>Lifelong Mapping<br>激光雷达<br>三维映射<br>三维重建<br>终身映射 | Input: Hand-held and robot-mounted LiDAR maps 输入：手持和机器人安装的激光雷达地图<br>Dynamic point removal algorithm 动态点去除算法<br>Multi-session map alignment using feature descriptor matching and fine registration 多会话地图对齐，使用特征描述符匹配和精细配准<br>Map change detection to identify changes between aligned maps 地图变化检测以识别对齐地图之间的变化<br>Map version control for maintaining current environmental state and querying changes 地图版本控制，用于维护当前环境状态和查询变化 |
8.0 | [[8.0] 2501.18595v1 ROSA: Reconstructing Object Shape and Appearance Textures by Adaptive Detail Transfer](http://arxiv.org/abs/2501.18595v1) | Mesh Reconstruction 网格重建 | Mesh Reconstruction<br>3D reconstruction<br>网格重建<br>三维重建 | input: limited set of images 限制的图像集<br>step1: optimize mesh geometry 优化网格几何形状<br>step2: refine mesh with spatially adaptive resolution 使用空间自适应分辨率细化网格<br>step3: reconstruct high-resolution textures 重新构建高分辨率纹理<br>output: textured mesh with detailed appearance 带有详细外观的纹理网格 |
7.5 | [[7.5] 2501.18590v1 DiffusionRenderer: Neural Inverse and Forward Rendering with Video Diffusion Models](http://arxiv.org/abs/2501.18590v1) | Rendering Techniques 渲染技术 | Inverse Rendering<br>Forward Rendering<br>Video Diffusion Models<br>Inverse渲染<br>正向渲染<br>视频扩散模型 | input: real-world videos, 真实世界视频<br>step1: estimate G-buffers using inverse rendering model, 使用逆向渲染模型估计G-buffer<br>step2: generate photorealistic images from G-buffers, 从G-buffer生成照片级真实图像<br>output: relit images, material edited images, realistic object insertions, 重新照明图像，材料编辑图像，逼真的物体插入 |
7.5 | [[7.5] 2501.18315v1 Surface Defect Identification using Bayesian Filtering on a 3D Mesh](http://arxiv.org/abs/2501.18315v1) | Mesh Reconstruction 网格重建 | 3D Mesh<br>Mesh Reconstruction<br>3D网格<br>网格重建 | input: CAD model and point cloud data 输入：CAD模型和点云数据<br>transform CAD model into polygonal mesh 将CAD模型转换为多边形网格<br>apply weighted least squares algorithm 应用加权最小二乘算法<br>estimate state based on point cloud measurements 根据点云测量估计状态<br>output: high-precision defect identification 输出：高精度缺陷识别 |
7.5 | [[7.5] 2501.17636v2 Efficient Interactive 3D Multi-Object Removal](http://arxiv.org/abs/2501.17636v2) | 3D reconstruction 三维重建 | 3D scene understanding<br>multi-object removal<br>3D场景理解<br>多对象移除 | input: selected areas and objects for removal 选定的移除区域和对象<br>step1: mask matching and refinement mask 匹配和细化掩码步骤<br>step2: homography-based warping 同伦变换基础的扭曲<br>step3: inpainting process 修复过程<br>output: modified 3D scene 修改后的3D场景 |
7.0 | [[7.0] 2501.18246v1 Ground Awareness in Deep Learning for Large Outdoor Point Cloud Segmentation](http://arxiv.org/abs/2501.18246v1) | 3D reconstruction  三维重建 | point cloud segmentation<br>outdoor point clouds<br>semantic segmentation<br>point cloud<br>关键点云分割<br>户外点云<br>语义分割<br>点云 | input: outdoor point clouds 户外点云<br>compute Digital Terrain Models (DTMs) 计算数字地形模型<br>employ RandLA-Net for segmentation 使用 RandLA-Net 进行分割<br>evaluate performance on datasets 评估在数据集上的表现<br>integrate relative elevation features 集成相对高程特征 |
6.5 | [[6.5] 2501.18494v1 Runway vs. Taxiway: Challenges in Automated Line Identification and Notation Approaches](http://arxiv.org/abs/2501.18494v1) | Autonomous Driving 自动驾驶 | Automated line identification 自动化线识别<br>Convolutional Neural Network 卷积神经网络<br>runway markings 跑道标记<br>autonomous systems 自动化系统<br>labeling algorithms 标记算法 | input: runway and taxiway images 跑道和滑行道图像<br>Step 1: color threshold adjustment 颜色阈值调整<br>Step 2: refine region of interest selection 精细化感兴趣区域选择<br>Step 3: integrate CNN classification 集成CNN分类<br>output: improved marking identification 改进的标记识别 |


## Newly Found Papers on ...
(Older entries get replaced automatically when the script runs again.)